{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f391e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12eebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and preprocess the data\n",
    "# DATASET_COLUMNS = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "# DATASET_ENCODING = \"ISO-8859-1\"\n",
    "# dataset = pd.read_csv('C:/Users/IDEH/Desktop/Sentimental/Data/Sentiment140.csv',\n",
    "#                       encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa566df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_map = {0: 0, 4: 1}  # 0: negative, 1: positive\n",
    "# dataset.loc[:, 'sentiment'] = dataset['sentiment'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ccdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(textdata):\n",
    "#     processedText = []\n",
    "#     wordLemm = WordNetLemmatizer()\n",
    "#     urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "#     userPattern = '@[^\\s]+'\n",
    "#     alphaPattern = \"[^a-zA-Z0-9]\"\n",
    "#     sequencePattern = r\"(.)\\1\\1+\"\n",
    "#     seqReplacePattern = r\"\\1\\1\"\n",
    "\n",
    "#     for tweet in tqdm(textdata, desc=\"Processing tweets\", unit=\"tweet\"):\n",
    "#         tweet = tweet.lower()\n",
    "#         tweet = re.sub(urlPattern, ' URL', tweet)\n",
    "#         tweet = re.sub(userPattern, ' USER', tweet)\n",
    "#         tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "#         tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "#         tweetwords = ''\n",
    "#         for word in tweet.split():\n",
    "#             word = wordLemm.lemmatize(word)\n",
    "#             tweetwords += (word + ' ')\n",
    "#         processedText.append(tweetwords)\n",
    "\n",
    "#     return processedText\n",
    "\n",
    "# processed_text = preprocess(dataset['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d5471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading text data: 100%|████████████████████████████████████████████████| 1600000/1600000 [00:00<00:00, 2019183.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data with a progress bar\n",
    "preprocessed_df = pd.read_csv('C:/Users/IDEH/Desktop/Sentimental/Data/preprocessed_data.csv')\n",
    "\n",
    "# Use tqdm to show progress for converting text column to list\n",
    "processed_text = [text for text in tqdm(preprocessed_df['text'], desc=\"Loading text data\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d196cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sentiment data: 100%|███████████████████████████████████████████| 1600000/1600000 [00:00<00:00, 2781176.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to show progress for converting sentiment column to numpy array\n",
    "Y = [sentiment for sentiment in tqdm(preprocessed_df['sentiment'], desc=\"Loading sentiment data\")]\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "701abd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting tokenizer: 100%|██████████████████████████████████████████████████| 1600000/1600000 [00:37<00:00, 42679.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Padding\n",
    "max_features = 10000\n",
    "max_len = 20  # Define max_len\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "\n",
    "# Use tqdm to show progress for fitting the tokenizer\n",
    "tokenizer.fit_on_texts(tqdm(processed_text, desc=\"Fitting tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03419e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting texts to sequences: 100%|██████████████████████████████████████| 1600000/1600000 [00:30<00:00, 52811.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to show progress for converting texts to sequences\n",
    "X = [tokenizer.texts_to_sequences([text])[0] for text in tqdm(processed_text, desc=\"Converting texts to sequences\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3941e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|████████████████████████████████████████████████| 1600000/1600000 [00:00<00:00, 3155161.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to show progress for padding sequences\n",
    "X = pad_sequences(tqdm(X, desc=\"Padding sequences\"), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61634b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7dd0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000, 20), (320000, 20), (1280000,), (320000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24406982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating clients:  80%|████████████████████████████████████████████████████             | 8/10 [00:00<00:00, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough samples for label 1 in client 1, selected 0 samples\n",
      "Not enough samples for label 1 in client 2, selected 0 samples\n",
      "Not enough samples for label 1 in client 3, selected 0 samples\n",
      "Not enough samples for label 1 in client 4, selected 0 samples\n",
      "Not enough samples for label 1 in client 5, selected 0 samples\n",
      "Not enough samples for label 1 in client 6, selected 0 samples\n",
      "Not enough samples for label 1 in client 7, selected 0 samples\n",
      "Not enough samples for label 1 in client 8, selected 0 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Creating clients: 100%|████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough samples for label 1 in client 9, selected 0 samples\n",
      "Not enough samples for label 1 in client 10, selected 0 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 10 clients\n",
    "num_clients = 10\n",
    "clients_data = []\n",
    "samples_per_label = 10  # Number of samples per label per client\n",
    "\n",
    "for i in tqdm(range(num_clients), desc=\"Creating clients\"):\n",
    "    client_X, client_y = [], []\n",
    "    for label in [0, 1]:\n",
    "        idx = np.where(y_train == label)[0]\n",
    "        if len(idx) >= samples_per_label:\n",
    "            selected_idx = np.random.choice(idx, size=samples_per_label, replace=False)\n",
    "        else:\n",
    "            selected_idx = np.random.choice(idx, size=len(idx), replace=False)  # Select all available samples\n",
    "            print(f\"Not enough samples for label {label} in client {i + 1}, selected {len(selected_idx)} samples\")\n",
    "        client_X.extend(X_train[selected_idx])\n",
    "        client_y.extend(y_train[selected_idx])\n",
    "    clients_data.append((np.array(client_X), np.array(client_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760377c5",
   "metadata": {},
   "source": [
    "Initialize Variables:<br/>\n",
    "num_clients = 10: Specifies the number of clients.\n",
    "clients_data = []: Initializes an empty list to store the data for each client.\n",
    "Loop Through Each Client:<br/>\n",
    "for i in range(num_clients): Loops through each client (from 0 to 9).<br/>\n",
    "Initialize Client Data:<br/>\n",
    "client_X, client_y = [], []:\n",
    "<br/> Initializes empty lists to store the features (client_X) and labels (client_y) for the current client.\n",
    "Loop Through Each Label:<br/>\n",
    "for label in [0, 1]:<br/> Loops through each label (0 and 1).<br/>\n",
    "Select Data for Each Label:<br/>\n",
    "idx = np.where(y_train == label)[0]:<br/> Finds the indices of all samples in y_train that have the current label.<br/>\n",
    "selected_idx = np.random.choice(idx, size=10, replace=False): Randomly selects 10 indices from the found indices without replacement.\n",
    "Add Selected Data to Client Data:<br/>\n",
    "client_X.extend(X_train[selected_idx]): Adds the selected features from X_train to client_X.<br/>\n",
    "client_y.extend(y_train[selected_idx]): Adds the selected labels from y_train to client_y.<br/>\n",
    "Store Client Data:<br/>\n",
    "clients_data.append((np.array(client_X), np.array(client_y))): Converts client_X and client_y to numpy arrays and appends them as a tuple to clients_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fd734c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0,    0,    0,    0,    0,   23,  105,  142,   72,\n",
       "         1684,  326,   16,    1,   65,   68,   98, 1530, 2612],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,   54,\n",
       "            5,  616,    7,  176, 3293,   24,  934,   91,   56],\n",
       "        [ 331,    8,   23,  177,   25,   24, 2913,   55, 4824,    1,  148,\n",
       "           72,  104, 2913,   62,   93,    3,    4, 2062,  173],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            1,   20,    5,  622, 7497,   16,    7,  376, 2599],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,  317,  236,   22,    5,\n",
       "          159,  289,   73,   62,  114,   41,  247,   16,   45],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  199,  331,    8, 4118,   82,    5,  509],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    2,   86,   69,    3,  236,  241,  150,   45],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0, 1687,    6,   13,  408],\n",
       "        [   1,   85,   25,  195,    7,  186, 1547,  289,  213,  878,  550,\n",
       "           28,  101,   85,   20,    7,  359,  201,   30,  157],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    1,   68,    3,   39, 2393,   65,  122]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d077bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "786e404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def federated_learning(X_train, y_train, X_test, y_test, num_clients=10, num_rounds=5, local_epochs=3):\n",
    "    # Create client data\n",
    "    clients_data = []\n",
    "    samples_per_client = len(X_train) // num_clients\n",
    "    for i in tqdm(range(num_clients), desc=\"Creating clients\"):\n",
    "        start = i * samples_per_client\n",
    "        end = (i + 1) * samples_per_client\n",
    "        clients_data.append((X_train[start:end], y_train[start:end]))\n",
    "\n",
    "    # Initialize global model\n",
    "    global_model = create_model()\n",
    "\n",
    "    for round in tqdm(range(num_rounds), desc=\"Federated learning rounds\"):\n",
    "        print(f\"Round {round + 1}/{num_rounds}\")\n",
    "        \n",
    "        client_models = []\n",
    "        \n",
    "        for i, (client_X, client_y) in enumerate(tqdm(clients_data, desc=\"Training clients\", leave=False)):\n",
    "            print(f\"Training on client {i + 1}/{num_clients}\")\n",
    "            client_model = tf.keras.models.clone_model(global_model)\n",
    "            client_model.set_weights(global_model.get_weights())\n",
    "            client_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Compile the model\n",
    "            client_model.fit(client_X, client_y, epochs=local_epochs, batch_size=32, verbose=0)\n",
    "            client_models.append(client_model)\n",
    "        \n",
    "        # Average the models\n",
    "        averaged_weights = [np.zeros_like(w) for w in global_model.get_weights()]\n",
    "        for client_model in tqdm(client_models, desc=\"Averaging models\", leave=False):\n",
    "            client_weights = client_model.get_weights()\n",
    "            for i in range(len(client_weights)):\n",
    "                averaged_weights[i] += client_weights[i]\n",
    "        averaged_weights = [w / num_clients for w in averaged_weights]\n",
    "        \n",
    "        global_model.set_weights(averaged_weights)\n",
    "        \n",
    "        # Evaluate global model\n",
    "        test_loss, test_accuracy = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return global_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72861941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating clients: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [00:00<?, ?it/s]\n",
      "Federated learning rounds:   0%|                                                                 | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training clients:   0%|                                                                         | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on client 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Federated learning rounds:   0%|                                                                 | 0/5 [05:22<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run Federated Learning\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m final_model \u001b[38;5;241m=\u001b[39m federated_learning(X_train, y_train, X_test, y_test)\n\u001b[0;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal training time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 25\u001b[0m, in \u001b[0;36mfederated_learning\u001b[1;34m(X_train, y_train, X_test, y_test, num_clients, num_rounds, local_epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m     client_model\u001b[38;5;241m.\u001b[39mset_weights(global_model\u001b[38;5;241m.\u001b[39mget_weights())\n\u001b[0;32m     24\u001b[0m     client_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     client_model\u001b[38;5;241m.\u001b[39mfit(client_X, client_y, epochs\u001b[38;5;241m=\u001b[39mlocal_epochs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m     client_models\u001b[38;5;241m.\u001b[39mappend(client_model)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Average the models\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run Federated Learning\n",
    "start_time = time.time()\n",
    "final_model = federated_learning(X_train, y_train, X_test, y_test)\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Federated Learning Rounds:   0%|                                                                 | 0/5 [00:00<?, ?it/s]\n",
      "Round 1 Client Training:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def federated_learning(X_train, y_train, X_test, y_test, num_clients=10, num_rounds=5, local_epochs=3, batch_size=32):\n",
    "    # Create client data\n",
    "    clients_data = []\n",
    "    samples_per_client = len(X_train) // num_clients\n",
    "    for i in range(num_clients):\n",
    "        start = i * samples_per_client\n",
    "        end = (i + 1) * samples_per_client\n",
    "        clients_data.append((X_train[start:end], y_train[start:end]))\n",
    "\n",
    "    # Initialize global model\n",
    "    global_model = create_model()\n",
    "\n",
    "    # Main federated learning loop\n",
    "    with tqdm(total=num_rounds, desc=\"Federated Learning Rounds\") as pbar_rounds:\n",
    "        for round in range(num_rounds):\n",
    "            client_models = []\n",
    "            \n",
    "            # Client training loop\n",
    "            with tqdm(total=num_clients, desc=f\"Round {round+1} Client Training\", leave=False) as pbar_clients:\n",
    "                for i, (client_X, client_y) in enumerate(clients_data):\n",
    "                    client_model = tf.keras.models.clone_model(global_model)\n",
    "                    client_model.set_weights(global_model.get_weights())\n",
    "                    client_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "                    \n",
    "                    # Train client model\n",
    "                    history = client_model.fit(\n",
    "                        client_X, client_y, \n",
    "                        epochs=local_epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        verbose=0,\n",
    "                        validation_split=0.1\n",
    "                    )\n",
    "                    \n",
    "                    client_models.append(client_model)\n",
    "                    pbar_clients.update(1)\n",
    "                    pbar_clients.set_postfix({'Client Acc': f\"{history.history['accuracy'][-1]:.4f}\"})\n",
    "\n",
    "            # Average the models\n",
    "            averaged_weights = [np.zeros_like(w) for w in global_model.get_weights()]\n",
    "            for client_model in client_models:\n",
    "                client_weights = client_model.get_weights()\n",
    "                for i in range(len(client_weights)):\n",
    "                    averaged_weights[i] += client_weights[i]\n",
    "            averaged_weights = [w / num_clients for w in averaged_weights]\n",
    "            \n",
    "            global_model.set_weights(averaged_weights)\n",
    "            \n",
    "            # Evaluate global model\n",
    "            test_loss, test_accuracy = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "            pbar_rounds.update(1)\n",
    "            pbar_rounds.set_postfix({'Test Acc': f\"{test_accuracy:.4f}\"})\n",
    "\n",
    "    return global_model\n",
    "\n",
    "# Run Federated Learning\n",
    "start_time = time.time()\n",
    "final_model = federated_learning(X_train, y_train, X_test, y_test, num_clients=10, num_rounds=5, local_epochs=3, batch_size=64)\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f020e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
