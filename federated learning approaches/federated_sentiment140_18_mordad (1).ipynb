{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxtzKFPPmxjN",
        "outputId": "cd6dc331-d587-4e7b-f5d5-1b968a2c4b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D,LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make data directory if it doesn't exist\n",
        "!mkdir -p data\n",
        "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip -P data\n",
        "!unzip -n -d data data/sentiment140-subset.csv.zip\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"data/sentiment140-subset.csv\")\n",
        "dataset = df[['polarity', 'text']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haLgMpqVm0fN",
        "outputId": "58cafafd-2f2a-4c32-93eb-0b512e6536d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-08 06:09:48--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip\n",
            "Resolving nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
            "Connecting to nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17927149 (17M) [application/zip]\n",
            "Saving to: ‘data/sentiment140-subset.csv.zip’\n",
            "\n",
            "\r          sentiment   0%[                    ]       0  --.-KB/s               \rsentiment140-subset 100%[===================>]  17.10M   114MB/s    in 0.2s    \n",
            "\n",
            "2024-08-08 06:09:49 (114 MB/s) - ‘data/sentiment140-subset.csv.zip’ saved [17927149/17927149]\n",
            "\n",
            "Archive:  data/sentiment140-subset.csv.zip\n",
            "  inflating: data/sentiment140-subset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvPe-3vJnOFp",
        "outputId": "44662d65-ae21-4bb2-f27a-fdad616887a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500000 entries, 0 to 499999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   polarity  500000 non-null  int64 \n",
            " 1   text      500000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance the dataset\n",
        "minority_count = dataset['polarity'].value_counts().min()\n",
        "balanced_df = pd.concat([\n",
        "    dataset[dataset['polarity'] == 0].sample(minority_count, replace=False),\n",
        "    dataset[dataset['polarity'] == 1].sample(minority_count, replace=False),\n",
        "]).sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "l4caF-sGm3mM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKJeG4bJnA1J",
        "outputId": "07a84652-a8d7-48e6-cf91-1e120e575f76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 499450 entries, 0 to 499449\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   polarity  499450 non-null  int64 \n",
            " 1   text      499450 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess(textdata):\n",
        "    processedText = []\n",
        "    wordLemm = WordNetLemmatizer()\n",
        "    urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern = '@[^\\s]+'\n",
        "    alphaPattern = \"[^a-zA-Z0-9]\"\n",
        "    sequencePattern = r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern = r\"\\1\\1\"\n",
        "    for tweet in tqdm(textdata, desc=\"Processing tweets\", unit=\"tweet\"):\n",
        "        tweet = str(tweet).lower()\n",
        "        tweet = re.sub(urlPattern, ' URL', tweet)\n",
        "        tweet = re.sub(userPattern, ' USER', tweet)\n",
        "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
        "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "        tweetwords = ''\n",
        "        for word in tweet.split():\n",
        "            word = wordLemm.lemmatize(word)\n",
        "            tweetwords += (word + ' ')\n",
        "        processedText.append(tweetwords)\n",
        "    return processedText\n",
        "\n",
        "processed_text = preprocess(balanced_df['text'].values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HR9t-rQnJCJ",
        "outputId": "cdf9db08-cd78-4aa9-c937-d699ae64d21a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets: 100%|██████████| 499450/499450 [00:45<00:00, 10971.76tweet/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "21uxJkcNoYLm",
        "outputId": "f6f1d0a7-9c57-44c7-c0a1-ea48ffe99d44"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'man not even a 10 minute drunken phone convo with one of my bmas can make me feel better sad time man i love you '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tqdm to show progress for converting sentiment column to numpy array\n",
        "Y = [sentiment for sentiment in tqdm(balanced_df['polarity'], desc=\"Loading sentiment data\")]\n",
        "Y = np.array(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOT-tbMuoNbP",
        "outputId": "483e42e9-a2ac-4f3f-b618-abfd0d251ae8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading sentiment data: 100%|██████████| 499450/499450 [00:00<00:00, 1477466.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Padding\n",
        "max_features = 10000\n",
        "max_len = 20  # Define max_len\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "# Use tqdm to show progress for fitting the tokenizer\n",
        "tokenizer.fit_on_texts(tqdm(processed_text, desc=\"Fitting tokenizer\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0s8bNGnUnl",
        "outputId": "ccc335f5-43b0-44c3-c287-09a5c1b7982f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting tokenizer: 100%|██████████| 499450/499450 [00:12<00:00, 39716.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tqdm to show progress for converting texts to sequences\n",
        "X = [tokenizer.texts_to_sequences([text])[0] for text in tqdm(processed_text, desc=\"Converting texts to sequences\")]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0VoS4wynvVg",
        "outputId": "16c62758-cbf8-45bf-df35-4f5b9ed5d6d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting texts to sequences: 100%|██████████| 499450/499450 [00:11<00:00, 42832.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tqdm to show progress for padding sequences\n",
        "X = pad_sequences(tqdm(X, desc=\"Padding sequences\"), maxlen=max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7Hl_uA5nzvF",
        "outputId": "e587b45e-61ec-4026-b496-09ab7f1c1d58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Padding sequences: 100%|██████████| 499450/499450 [00:00<00:00, 1407795.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "BAzzTmrbn1zT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 10 clients\n",
        "num_clients = 10\n",
        "clients_data = []\n",
        "samples_per_label = 10  # Number of samples per label per client\n",
        "\n",
        "for i in tqdm(range(num_clients), desc=\"Creating clients\"):\n",
        "    client_X, client_y = [], []\n",
        "    for label in [0, 1]:\n",
        "        idx = np.where(y_train == label)[0]\n",
        "        if len(idx) >= samples_per_label:\n",
        "            selected_idx = np.random.choice(idx, size=samples_per_label, replace=False)\n",
        "        else:\n",
        "            selected_idx = np.random.choice(idx, size=len(idx), replace=False)  # Select all available samples\n",
        "            print(f\"Not enough samples for label {label} in client {i + 1}, selected {len(selected_idx)} samples\")\n",
        "        client_X.extend(X_train[selected_idx])\n",
        "        client_y.extend(y_train[selected_idx])\n",
        "    clients_data.append((np.array(client_X), np.array(client_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUQYc4s6n4fC",
        "outputId": "fd09ba3c-951d-4713-b0f4-c0ba15c83af3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating clients: 100%|██████████| 10/10 [00:00<00:00, 64.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clients_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InGroWwypPEA",
        "outputId": "ce065b42-3fef-4450-be44-5fd0f906b120"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   0,    0,    2,   85,   29,   92,  861, 1035,    5,  360,  181,\n",
              "         1565,   27,  498,   59,  157,   11,    5,  270,  139],\n",
              "        [   0,    0,    0,    0,    0,    2,   54,    6,    1,   23, 1673,\n",
              "           11,    9,    8,    1,  154,   15,   71, 6678,  129],\n",
              "        [ 290,   15,   38,    7,  396,   79,    1,   66,  465,    3,   20,\n",
              "           96,  878,  546,    4,  278, 2248, 1808,   59, 2223],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    2,  148, 4598,  544,   18, 2229],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    1,   66, 4843,\n",
              "            7, 7703,  530, 1452,    6,  524, 1871,   58,  139],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    2,    1,   68,    3,   25,   24,    9],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,   10,   26,   45],\n",
              "        [  11,   62,   96,  152,  294, 6510,   68,    3,   71,   18,   46,\n",
              "           22,    1,   32,   15,  222,    1,   20,   41,  427],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0, 2523,    1,   23,\n",
              "         6271,    7, 4211,   16,    4, 2087,   14,    7, 1549],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  243,\n",
              "            3,   35, 3710,    3,  451,  309,  382,   29, 2507],\n",
              "        [   2,  113,  559,   18,   96, 1711,  845,  934, 1208, 3742,    8,\n",
              "           73,  360,    1,   47,    4,  662, 2551,   49,  115],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    7,  178,   10,  254,  264,  926, 2401],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    2,  367,    1,\n",
              "           21,  138,  271,    3,  116,   31,   71,    9,  169],\n",
              "        [ 587,   43,   43,   86,   17,  311,   18, 1178, 5881,  250, 1491,\n",
              "           61,   27,   25,   16,    7,  198,  683,   11, 1472],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,   64,  204,  282,  236,   31],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,   52,    3,  366,    7,\n",
              "         2341,   31,    8,    7,    3,  819,    5, 1046,  386],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,   34,   29,  312,\n",
              "            5,  360,  185,    1, 1294,   38,   50,  109,   56],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    2,    1,   21, 1101,\n",
              "           22,  189,    5,   33,   50,  289,    7, 2152, 9611],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,   86,    1,\n",
              "           54,    6,    2,  175,  501, 2524,   17,   95,  171],\n",
              "        [   0,    0,    0,    7, 1143,   10, 3861,   34,    8,  170,   85,\n",
              "           23,   54,    5,  708,  911, 1314,  131, 2981, 3908]],\n",
              "       dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "sMQmVc05pTLN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_learning(X_train, y_train, X_test, y_test, num_clients=1, num_rounds=1, local_epochs=1):\n",
        "    # Split the data among clients\n",
        "    client_data = np.array_split(X_train, num_clients)\n",
        "    client_labels = np.array_split(y_train, num_clients)\n",
        "\n",
        "    # Initialize the global model\n",
        "    global_model = create_model()\n",
        "    global_model.build(input_shape=(None, X_train.shape[1]))  # Ensure the model is built\n",
        "\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"Round {round_num+1}/{num_rounds}\")\n",
        "\n",
        "        # Initialize the list to store client weights\n",
        "        client_weights_list = []\n",
        "\n",
        "        for client_num in range(num_clients):\n",
        "            print(f\"Training on client {client_num+1}/{num_clients}\")\n",
        "\n",
        "            # Create a new model for each client\n",
        "            client_model = create_model()\n",
        "            client_model.build(input_shape=(None, X_train.shape[1]))  # Ensure the model is built\n",
        "            client_model.set_weights(global_model.get_weights())\n",
        "\n",
        "            # Train the client model\n",
        "            client_model.fit(client_data[client_num], client_labels[client_num], epochs=local_epochs, verbose=0)\n",
        "\n",
        "            # Append the client weights to the list\n",
        "            client_weights_list.append(client_model.get_weights())\n",
        "\n",
        "        # Average the client weights\n",
        "        averaged_weights = [np.zeros_like(w) for w in client_weights_list[0]]\n",
        "        for client_weights in client_weights_list:\n",
        "            for i in range(len(client_weights)):\n",
        "                averaged_weights[i] += client_weights[i]\n",
        "        averaged_weights = [w / num_clients for w in averaged_weights]\n",
        "\n",
        "        # Set the global model weights to the averaged weights\n",
        "        global_model.set_weights(averaged_weights)\n",
        "\n",
        "    # Evaluate the global model\n",
        "    loss, accuracy = global_model.evaluate(X_test, y_test)\n",
        "    print(f\"Final model accuracy: {accuracy}\")\n",
        "\n",
        "    return global_model"
      ],
      "metadata": {
        "id": "KjelneDwpUWh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Federated Learning\n",
        "start_time = time.time()\n",
        "final_model = federated_learning(X_train, y_train, X_test, y_test)\n",
        "end_time = time.time()\n",
        "print(f\"Total training time: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJv6-1Sdpayd",
        "outputId": "9d739d8d-e4a7-49fc-c381-d0898fa7807e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/1\n",
            "Training on client 1/1\n",
            "\u001b[1m3122/3122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4145\n",
            "Final model accuracy: 0.8095705509185791\n",
            "Total training time: 333.32 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3w_de1jzpvN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}